diff --git a/bin/exec.py b/bin/exec.py
index fc9a18c..b250328 100755
--- a/bin/exec.py
+++ b/bin/exec.py
@@ -249,7 +249,7 @@ class exec(object):
             if self.args.data.data_format == DataFormatKind.channels_last:
                 if self.args.run.compute_mode == ComputeMode.GPU:
                     logger.warning("CUDA Torch requires channels_first, switching automatically")
-                    self.args.data.data_format = DataFormatKind.channels_first
+                self.args.data.data_format = DataFormatKind.channels_first

         elif self.args.framework.name == "tensorflow":
             if self.args.mode.name == ModeKind.train:
@@ -261,7 +261,7 @@ class exec(object):



-@hydra.main(version_base=None, config_path="../src/config", config_name="config")
+@hydra.main(config_path="../src/config", config_name="config")
 def main(cfg : OmegaConf) -> None:

     s = exec(cfg)


diff --git a/cosmic_tagger.dist_hpu.v1.6.0.diff b/cosmic_tagger.dist_hpu.v1.6.0.diff
new file mode 100644
index 0000000..607d8bd
--- /dev/null
+++ b/cosmic_tagger.dist_hpu.v1.6.0.diff
@@ -0,0 +1,263 @@


+diff --git a/requirements.txt b/requirements.txt
+index 6e8a7b9..e959223 100644
+--- a/requirements.txt
++++ b/requirements.txt
+@@ -1,8 +1,8 @@
+ numpy
+ h5py
+ larcv
+-tensorflow>=2.4.0
+-torch>=1.3
++# tensorflow>=2.4.0
++# torch>=1.3
+ Pillow # Needed for tensorboardX
+ tensorboardX
+ hydra-core==1.1
+diff --git a/src/config/config.py b/src/config/config.py
+index b060114..9d0a090 100644
+--- a/src/config/config.py
++++ b/src/config/config.py
+@@ -15,6 +15,7 @@ class ComputeMode(Enum):
+     GPU   = 1
+     DPCPP = 2
+     XPU   = 3
++    HPU   = 4
+
+ class Precision(Enum):
+     float32  = 0
+@@ -40,6 +41,7 @@ class Run:
+     id:                 str         = MISSING
+     precision:          Precision   = Precision.float32
+     profile:            bool        = False
++    lazy_mode:          bool        = False
+
+ cs = ConfigStore.instance()
+
+diff --git a/src/config/data.py b/src/config/data.py
+index 7daba3e..bf5596b 100644
+--- a/src/config/data.py
++++ b/src/config/data.py
+@@ -30,4 +30,4 @@ class Synthetic(Data):
+
+ cs = ConfigStore.instance()
+ cs.store(group="data", name="real", node=Real)
+-cs.store(group="data", name="synthetic", node=Synthetic)
+\ No newline at end of file
++cs.store(group="data", name="synthetic", node=Synthetic)
+diff --git a/src/utils/tensorflow2/trainer.py b/src/utils/tensorflow2/trainer.py
+index 69cc804..e0ab814 100644
+--- a/src/utils/tensorflow2/trainer.py
++++ b/src/utils/tensorflow2/trainer.py
+@@ -183,6 +183,9 @@ class tf_trainer(trainercore):
+
+     def initialize(self, io_only=False):
+
++        if self.args.run.compute_mode == ComputeMode.HPU:
++            from habana_frameworks.tensorflow import load_habana_module
++            load_habana_module()
+
+         self._initialize_io(color=0)
+
+diff --git a/src/utils/torch/distributed_trainer.py b/src/utils/torch/distributed_trainer.py
+index 433ba96..e8a21c6 100644
+--- a/src/utils/torch/distributed_trainer.py
++++ b/src/utils/torch/distributed_trainer.py
+@@ -16,6 +16,7 @@ try:
+ except:
+     pass
+
++import contextlib
+ import logging
+ logger = logging.getLogger()
+ logger.propogate = False
+@@ -98,7 +99,10 @@ class distributed_trainer(torch_trainer):
+             size = MPI.COMM_WORLD.Get_size()
+             rank = MPI.COMM_WORLD.Get_rank()
+
+-            torch.cuda.set_device(int(local_rank))
++            if self.args.run.compute_mode == ComputeMode.HPU:
++                import habana_frameworks.torch.distributed.hccl
++            else:
++                torch.cuda.set_device(int(local_rank))
+
+
+             os.environ["RANK"] = str(rank)
+@@ -131,17 +135,24 @@ class distributed_trainer(torch_trainer):
+                 backend = 'ccl'
+             elif self.args.run.compute_mode == ComputeMode.GPU: backend = 'nccl'
+             elif self.args.run.compute_mode == ComputeMode.CPU: backend = 'gloo'
++            elif self.args.run.compute_mode == ComputeMode.HPU: backend = 'hccl'
+
+             # init_method = 'file:///home/cadams/ddp_init/ddp_init.txt'
+             init_method = 'env://'
+
+-            torch.distributed.init_process_group(
+-                backend     = backend,
+-                init_method = init_method,
+-                world_size  = size,
+-                rank        = rank,
+-                timeout     = datetime.timedelta(seconds=120)
+-            )
++            if self.args.run.compute_mode == ComputeMode.HPU:
++                # Here we assume the number of process per node is 8
++                os.environ["ID"] = str(rank % 8 )
++                os.environ["LOCAL_RANK"] = str(rank % 8 )
++                torch.distributed.init_process_group(backend=backend, rank=rank, world_size=size)
++            else:
++                torch.distributed.init_process_group(
++                    backend     = backend,
++                    init_method = init_method,
++                    world_size  = size,
++                    rank        = rank,
++                    timeout     = datetime.timedelta(seconds=120)
++                )
+
+
+     def save_model(self):
+@@ -169,7 +180,7 @@ class distributed_trainer(torch_trainer):
+             return contextlib.nullcontext
+             # device = torch.device("dpcpp")
+         else:
+-            return contextlib.nullcontext
++            return contextlib.nullcontext()
+             # device = torch.device('cpu')
+
+     def default_device(self):
+@@ -184,6 +195,8 @@ class distributed_trainer(torch_trainer):
+             device = torch.device(f"xpu:{self._local_rank}")
+         elif self.args.run.compute_mode == ComputeMode.DPCPP:
+             device = torch.device("dpcpp")
++        elif self.args.run.compute_mode == ComputeMode.HPU:
++            device = torch.device("hpu")
+         else:
+             device = torch.device('cpu')
+         return device
+diff --git a/src/utils/torch/trainer.py b/src/utils/torch/trainer.py
+index 71b6cf3..46a6fb7 100644
+--- a/src/utils/torch/trainer.py
++++ b/src/utils/torch/trainer.py
+@@ -1,4 +1,6 @@
+ import os
++from pickle import TRUE
++from re import I
+ import sys
+ import time
+ import tempfile
+@@ -96,6 +98,16 @@ class torch_trainer(trainercore):
+         if self.is_training():
+             self.build_lr_schedule()
+
++        if self.args.run.compute_mode == ComputeMode.HPU:
++
++            import habana_frameworks.torch.core as htcore
++            self.htcore = htcore
++
++            if self.args.run.lazy_mode:
++                os.environ["PT_HPU_LAZY_MODE"]="1"
++            else:
++                os.environ["PT_HPU_LAZY_MODE"]="2"
++
+         with self.default_device_context():
+             self.init_network()
+
+@@ -462,7 +474,7 @@ class torch_trainer(trainercore):
+
+             # Build up a string for logging:
+             if self._log_keys != []:
+-                s = ", ".join(["{0}: {1:.3}".format(key, metrics[key]) for key in self._log_keys])
++                s = ", ".join(["{0}: {1:.3}".format(key, metrics[key].item()) for key in self._log_keys])
+             else:
+                 s = ", ".join(["{0}: {1:.3}".format(key, metrics[key]) for key in metrics])
+
+@@ -598,8 +610,10 @@ class torch_trainer(trainercore):
+         # elif self.args.run.compute_mode == "DPCPP":
+         #     return contextlib.nullcontext
+         #     # device = torch.device("dpcpp")
++        elif self.args.run.compute_mode == ComputeMode.HPU:
++            return contextlib.nullcontext()
+         else:
+-            return contextlib.nullcontext
++            return contextlib.nullcontext()
+             # device = torch.device('cpu')
+
+     def default_device(self):
+@@ -610,6 +624,8 @@ class torch_trainer(trainercore):
+             device = torch.device("xpu")
+         # elif self.args.run.compute_mode == "DPCPP":
+         #     device = torch.device("dpcpp")
++        elif self.args.run.compute_mode == ComputeMode.HPU:
++            device = torch.device("hpu")
+         else:
+             device = torch.device('cpu')
+         return device
+@@ -733,8 +749,8 @@ class torch_trainer(trainercore):
+                     else:
+                         loss.backward()
+
+-
+-
++                    if self.args.run.lazy_mode:
++                        self.htcore.mark_step()
+
+                     # Compute any necessary metrics:
+                     interior_metrics = self._compute_metrics(logits_image, labels_image, loss)
+@@ -776,6 +792,9 @@ class torch_trainer(trainercore):
+             else:
+                 self._opt.step()
+
++            if self.args.run.lazy_mode:
++                self.htcore.mark_step()
++
+             self.lr_scheduler.step()
+
+             if verbose: logger.debug("Updated Weights")
+@@ -816,30 +835,31 @@ class torch_trainer(trainercore):
+         # fit onto a gpu or other accelerator
+         if self._global_step != 0 and self._global_step % self.args.run.aux_iterations == 0:
+
+-            self._net.eval()
+-            # Fetch the next batch of data with larcv
+-            # (Make sure to pull from the validation set)
+-            io_start_time = datetime.datetime.now()
+-            minibatch_data = self.larcv_fetcher.fetch_next_batch('aux', force_pop = True)
+-            io_end_time = datetime.datetime.now()
++            with torch.no_grad():
++                self._net.eval()
++                # Fetch the next batch of data with larcv
++                # (Make sure to pull from the validation set)
++                io_start_time = datetime.datetime.now()
++                minibatch_data = self.larcv_fetcher.fetch_next_batch('aux', force_pop = True)
++                io_end_time = datetime.datetime.now()
+
+-            # if mixed precision, and cuda, use autocast:
+-            if self.args.run.precision == Precision.mixed and self.args.run.compute_mode == ComputeMode.GPU:
+-                with torch.cuda.amp.autocast():
++                # if mixed precision, and cuda, use autocast:
++                if self.args.run.precision == Precision.mixed and self.args.run.compute_mode == ComputeMode.GPU:
++                    with torch.cuda.amp.autocast():
++                        logits_image, labels_image = self.forward_pass(minibatch_data)
++                else:
+                     logits_image, labels_image = self.forward_pass(minibatch_data)
+-            else:
+-                logits_image, labels_image = self.forward_pass(minibatch_data)
+
+-            # Compute the loss based on the logits
+-            loss = self.loss_calculator(labels_image, logits_image)
++                # Compute the loss based on the logits
++                loss = self.loss_calculator(labels_image, logits_image)
+
+-            # Compute any necessary metrics:
+-            metrics = self._compute_metrics(logits_image, labels_image, loss)
++                # Compute any necessary metrics:
++                metrics = self._compute_metrics(logits_image, labels_image, loss)
+
+
+-            self.log(metrics, saver="test")
+-            self.summary(metrics, saver="test")
+-            self.summary_images(logits_image, labels_image, saver="test")
++                self.log(metrics, saver="test")
++                self.summary(metrics, saver="test")
++                self.summary_images(logits_image, labels_image, saver="test")
+
+             return
+
diff --git a/src/config/config.py b/src/config/config.py
index b060114..9d0a090 100644
--- a/src/config/config.py
+++ b/src/config/config.py
@@ -15,6 +15,7 @@ class ComputeMode(Enum):
     GPU   = 1
     DPCPP = 2
     XPU   = 3
+    HPU   = 4

 class Precision(Enum):
     float32  = 0
@@ -40,6 +41,7 @@ class Run:
     id:                 str         = MISSING
     precision:          Precision   = Precision.float32
     profile:            bool        = False
+    lazy_mode:          bool        = False

 cs = ConfigStore.instance()

diff --git a/src/utils/tensorflow2/trainer.py b/src/utils/tensorflow2/trainer.py
index cc66b72..590513f 100644
--- a/src/utils/tensorflow2/trainer.py
+++ b/src/utils/tensorflow2/trainer.py
@@ -184,6 +184,9 @@ class tf_trainer(trainercore):

     def initialize(self, io_only=False):

+        if self.args.run.compute_mode == ComputeMode.HPU:
+            from habana_frameworks.tensorflow import load_habana_module
+            load_habana_module()

         self._initialize_io(color=0)

diff --git a/src/utils/torch/distributed_trainer.py b/src/utils/torch/distributed_trainer.py
index b1144d5..e95641e 100644
--- a/src/utils/torch/distributed_trainer.py
+++ b/src/utils/torch/distributed_trainer.py
@@ -102,6 +102,11 @@ class distributed_trainer(torch_trainer):
             size = MPI.COMM_WORLD.Get_size()
             rank = MPI.COMM_WORLD.Get_rank()

+            if self.args.run.compute_mode == ComputeMode.HPU:
+                import habana_frameworks.torch.distributed.hccl
+            else:
+                torch.cuda.set_device(int(local_rank))
+

             os.environ["RANK"] = str(rank)
             os.environ["WORLD_SIZE"] = str(size)
@@ -133,17 +138,24 @@ class distributed_trainer(torch_trainer):
                 backend = 'ccl'
             elif self.args.run.compute_mode == ComputeMode.GPU: backend = 'nccl'
             elif self.args.run.compute_mode == ComputeMode.CPU: backend = 'gloo'
+            elif self.args.run.compute_mode == ComputeMode.HPU: backend = 'hccl'

             # init_method = 'file:///home/cadams/ddp_init/ddp_init.txt'
             init_method = 'env://'

-            torch.distributed.init_process_group(
-                backend     = backend,
-                init_method = init_method,
-                world_size  = size,
-                rank        = rank,
-                timeout     = datetime.timedelta(seconds=120)
-            )
+            if self.args.run.compute_mode == ComputeMode.HPU:
+                # Here we assume the number of process per node is 8
+                os.environ["ID"] = str(rank % 8 )
+                os.environ["LOCAL_RANK"] = str(rank % 8 )
+                torch.distributed.init_process_group(backend=backend, rank=rank, world_size=size)
+            else:
+                torch.distributed.init_process_group(
+                    backend     = backend,
+                    init_method = init_method,
+                    world_size  = size,
+                    rank        = rank,
+                    timeout     = datetime.timedelta(seconds=120)
+                )


     def save_model(self):
@@ -189,6 +201,8 @@ class distributed_trainer(torch_trainer):
             device = torch.device(f"xpu:{self._local_rank}")
         elif self.args.run.compute_mode == ComputeMode.DPCPP:
             device = torch.device("dpcpp")
+        elif self.args.run.compute_mode == ComputeMode.HPU:
+            device = torch.device("hpu")
         else:
             device = torch.device('cpu')
         return device
diff --git a/src/utils/torch/trainer.py b/src/utils/torch/trainer.py
index 6a0f153..8674f19 100644
--- a/src/utils/torch/trainer.py
+++ b/src/utils/torch/trainer.py
@@ -104,6 +104,16 @@ class torch_trainer(trainercore):
         if self.is_training():
             self.build_lr_schedule()

+        if self.args.run.compute_mode == ComputeMode.HPU:
+
+            import habana_frameworks.torch.core as htcore
+            self.htcore = htcore
+
+            if self.args.run.lazy_mode:
+                os.environ["PT_HPU_LAZY_MODE"]="1"
+            else:
+                os.environ["PT_HPU_LAZY_MODE"]="2"
+
         with self.default_device_context():
             self.init_network()

@@ -472,7 +482,7 @@ class torch_trainer(trainercore):

             # Build up a string for logging:
             if self._log_keys != []:
-                s = ", ".join(["{0}: {1:.3}".format(key, metrics[key]) for key in self._log_keys])
+                s = ", ".join(["{0}: {1:.3}".format(key, metrics[key].item()) for key in self._log_keys])
             else:
                 s = ", ".join(["{0}: {1:.3}".format(key, metrics[key]) for key in metrics])

@@ -596,7 +606,7 @@ class torch_trainer(trainercore):
         if self.args.run.compute_mode == ComputeMode.GPU:
             return torch.cuda.device(0)
         elif self.args.run.compute_mode == ComputeMode.XPU:
-            # return contextlib.nullcontext
+            # return contextlib.nullcontext()
             try:
                 return ipex.xpu.device("xpu:0")
             except:
@@ -609,6 +619,8 @@ class torch_trainer(trainercore):
         # elif self.args.run.compute_mode == "DPCPP":
         #     return contextlib.nullcontext()
         #     # device = torch.device("dpcpp")
+        elif self.args.run.compute_mode == ComputeMode.HPU:
+            return contextlib.nullcontext()
         else:
             return contextlib.nullcontext()
             # device = torch.device('cpu')
@@ -621,6 +633,8 @@ class torch_trainer(trainercore):
             device = torch.device("xpu")
         # elif self.args.run.compute_mode == "DPCPP":
         #     device = torch.device("dpcpp")
+        elif self.args.run.compute_mode == ComputeMode.HPU:
+            device = torch.device("hpu")
         else:
             device = torch.device('cpu')
         return device
@@ -761,6 +775,8 @@ class torch_trainer(trainercore):
                         else:
                             loss.backward()

+                    if self.args.run.lazy_mode:
+                        self.htcore.mark_step()

                     # Compute any necessary metrics:
                     with self.timing_context("metrics"):
@@ -806,6 +822,9 @@ class torch_trainer(trainercore):

                 self.lr_scheduler.step()

+            if self.args.run.lazy_mode:
+                self.htcore.mark_step()
+
             if verbose: logger.debug("Updated Weights")
             global_end_time = datetime.datetime.now()

@@ -845,35 +864,36 @@ class torch_trainer(trainercore):
         # fit onto a gpu or other accelerator
         if self._global_step != 0 and self._global_step % self.args.run.aux_iterations == 0:

-            self._net.eval()
-            if self.args.run.compute_mode == ComputeMode.CPU:
-                # Quantization not supported on CUDA
-                val_net = torch.quantization.convert(self._net)
-            else:
-                val_net = self._net
-            # Fetch the next batch of data with larcv
-            # (Make sure to pull from the validation set)
-            io_start_time = datetime.datetime.now()
-            with self.timing_context("io"):
-                minibatch_data = self.larcv_fetcher.fetch_next_batch('aux', force_pop = True)
-            io_end_time = datetime.datetime.now()
-
-            # if mixed precision, and cuda, use autocast:
-            if self.args.run.precision == Precision.mixed and self.args.run.compute_mode == ComputeMode.GPU:
-                with torch.cuda.amp.autocast():
+            with torch.no_grad():
+                self._net.eval()
+                if self.args.run.compute_mode == ComputeMode.CPU:
+                    # Quantization not supported on CUDA
+                    val_net = torch.quantization.convert(self._net)
+                else:
+                    val_net = self._net
+                # Fetch the next batch of data with larcv
+                # (Make sure to pull from the validation set)
+                io_start_time = datetime.datetime.now()
+                with self.timing_context("io"):
+                    minibatch_data = self.larcv_fetcher.fetch_next_batch('aux', force_pop = True)
+                io_end_time = datetime.datetime.now()
+
+                # if mixed precision, and cuda, use autocast:
+                if self.args.run.precision == Precision.mixed and self.args.run.compute_mode == ComputeMode.GPU:
+                    with torch.cuda.amp.autocast():
+                        logits_image, labels_image = self.forward_pass(minibatch_data, net=val_net)
+                else:
                     logits_image, labels_image = self.forward_pass(minibatch_data, net=val_net)
-            else:
-                logits_image, labels_image = self.forward_pass(minibatch_data, net=val_net)

-            # Compute the loss based on the logits
-            loss = self.loss_calculator(labels_image, logits_image)
+                # Compute the loss based on the logits
+                loss = self.loss_calculator(labels_image, logits_image)

-            # Compute any necessary metrics:
-            metrics = self._compute_metrics(logits_image, labels_image, loss)
+                # Compute any necessary metrics:
+                metrics = self._compute_metrics(logits_image, labels_image, loss)

-            self.log(metrics, saver="test")
-            self.summary(metrics, saver="test")
-            self.summary_images(logits_image, labels_image, saver="test")
+                self.log(metrics, saver="test")
+                self.summary(metrics, saver="test")
+                self.summary_images(logits_image, labels_image, saver="test")

             return

