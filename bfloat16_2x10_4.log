18:25:13.317 777907 POPRUN [I] V-IPU server address picked up from 'vipu': 10.1.3.101:8090
18:25:13.320 777907 POPRUN [I] Using V-IPU partition p64 as it is the only one available
18:25:13.320 777907 POPRUN [D] Connecting to 10.1.3.101:8090
18:25:13.322 777907 POPRUN [D] Status for partition p64: OK (error 0)
18:25:13.322 777907 POPRUN [I] Partition p64 already exists and is in state: PS_ACTIVE
18:25:13.324 777907 POPRUN [D] The reconfigurable partition p64 is OK
 ===========================
|      poprun topology      |
|===========================|
| hosts     |   localhost   |
|-----------|---------------|
| ILDs      |       0       |
|-----------|---------------|
| instances | 0 | 1 | 2 | 3 |
|-----------|---------------|
| replicas  | 0 | 1 | 2 | 3 |
 ---------------------------
18:25:13.326 777907 POPRUN [D] Target options from environment: {}
18:25:13.326 777907 POPRUN [D] Target options from V-IPU partition: {"ipuLinkDomainSize":"64","ipuLinkConfiguration":"slidingWindow","ipuLinkTopology":"mesh","gatewayMode":"true","instanceSize":"16"}
18:25:13.841 777907 POPRUN [D] Found 16 devices with 4 IPUs
2023-02-03T18:25:14.285316Z ipuof_lib 777907.777943 E: attach_device_impl: Device already in use, device 3, IP 10.1.5.1:50052
2023-02-03T18:25:14.613439Z PO:TARGET   777907.777907 E: Failed to attach to ipu(s)
18:25:14.613 777907 POPRUN [D] Failed to attach to device 96
18:25:15.955 777907 POPRUN [D] Attached to device 97
18:25:15.955 777907 POPRUN [D] Found 4 children (expected 4) of device 97 with 1 IPUs each
18:25:15.957 777907 POPRUN [I] Preparing parent device 97
18:25:15.957 777907 POPRUN [D] Device 97 ipuLinkDomainSize=64, ipuLinkConfiguration=Default, ipuLinkTopology=Mesh, gatewayMode=true, instanceSize=1
18:25:18.473 777907 POPRUN [D] Target options from Poplar device: {"ipuLinkDomainSize":"64","ipuLinkConfiguration":"default","ipuLinkTopology":"mesh","gatewayMode":"true","instanceSize":"1"}
18:25:18.474 777907 POPRUN [D] Using target options: {"ipuLinkDomainSize":"64","ipuLinkConfiguration":"slidingWindow","ipuLinkTopology":"mesh","gatewayMode":"true","instanceSize":"16"}
18:25:18.509 777907 POPRUN [D] Skipping port 1 of IB device uverbs0 because its state (1) doesn't seem active. Information in sysfs might be invalid or might not exist
18:25:18.520 777907 POPRUN [D] Skipping port 1 of IB device uverbs1 because its state (1) doesn't seem active. Information in sysfs might be invalid or might not exist
18:25:18.570 777907 POPRUN [D] No hosts specified; ignoring host-subnet setting
18:25:18.570 777907 POPRUN [D] Default network/RNIC for host communication: None
18:25:18.571 777907 POPRUN [I] Running command: /software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/bin/mpirun '--bind-to' 'none' '--tag-output' '--allow-run-as-root' '-np' '1' '-x' 'POPDIST_NUM_TOTAL_REPLICAS=4' '-x' 'POPDIST_NUM_IPUS_PER_REPLICA=1' '-x' 'POPDIST_NUM_LOCAL_REPLICAS=1' '-x' 'POPDIST_UNIFORM_REPLICAS_PER_INSTANCE=1' '-x' 'POPDIST_NODE_DEVICE_ID=97' '-x' 'POPDIST_EXECUTABLE_CACHE_PATH=/home/wilsonb/tmp' '-x' 'POPDIST_REPLICA_INDEX_OFFSET=0' '-x' 'POPDIST_LOCAL_INSTANCE_INDEX=0' '-x' 'IPUOF_VIPU_API_HOST=10.1.3.101' '-x' 'IPUOF_VIPU_API_PORT=8090' '-x' 'IPUOF_VIPU_API_PARTITION_ID=p64' '-x' 'IPUOF_VIPU_API_TIMEOUT=120' '-x' 'IPUOF_LOG_LEVEL=WARN' '-x' 'PATH' '-x' 'LD_LIBRARY_PATH' '-x' 'PYTHONPATH' '-x' 'POPLAR_TARGET_OPTIONS={"ipuLinkDomainSize":"64","ipuLinkConfiguration":"slidingWindow","ipuLinkTopology":"mesh","gatewayMode":"true","instanceSize":"16"}' 'poprun_numa_wrapper' 'python' 'bin/exec.py' '--config-name=a21' 'mode=train' 'run.id=' 'run.distributed=False' 'data=real' 'data.data_directory=/lambda_stor/data/datascience/cosmic_tagging/' 'framework=torch' 'run.compute_mode=IPU' 'run.minibatch_size=2' 'run.iterations=10' 'run.precision=3' ':' '-np' '1' '-x' 'POPDIST_NUM_TOTAL_REPLICAS=4' '-x' 'POPDIST_NUM_IPUS_PER_REPLICA=1' '-x' 'POPDIST_NUM_LOCAL_REPLICAS=1' '-x' 'POPDIST_UNIFORM_REPLICAS_PER_INSTANCE=1' '-x' 'POPDIST_NODE_DEVICE_ID=97' '-x' 'POPDIST_EXECUTABLE_CACHE_PATH=/home/wilsonb/tmp' '-x' 'POPDIST_REPLICA_INDEX_OFFSET=1' '-x' 'POPDIST_LOCAL_INSTANCE_INDEX=1' '-x' 'IPUOF_VIPU_API_HOST=10.1.3.101' '-x' 'IPUOF_VIPU_API_PORT=8090' '-x' 'IPUOF_VIPU_API_PARTITION_ID=p64' '-x' 'IPUOF_VIPU_API_TIMEOUT=120' '-x' 'IPUOF_LOG_LEVEL=WARN' '-x' 'PATH' '-x' 'LD_LIBRARY_PATH' '-x' 'PYTHONPATH' '-x' 'POPLAR_TARGET_OPTIONS={"ipuLinkDomainSize":"64","ipuLinkConfiguration":"slidingWindow","ipuLinkTopology":"mesh","gatewayMode":"true","instanceSize":"16"}' 'poprun_numa_wrapper' 'python' 'bin/exec.py' '--config-name=a21' 'mode=train' 'run.id=' 'run.distributed=False' 'data=real' 'data.data_directory=/lambda_stor/data/datascience/cosmic_tagging/' 'framework=torch' 'run.compute_mode=IPU' 'run.minibatch_size=2' 'run.iterations=10' 'run.precision=3' ':' '-np' '1' '-x' 'POPDIST_NUM_TOTAL_REPLICAS=4' '-x' 'POPDIST_NUM_IPUS_PER_REPLICA=1' '-x' 'POPDIST_NUM_LOCAL_REPLICAS=1' '-x' 'POPDIST_UNIFORM_REPLICAS_PER_INSTANCE=1' '-x' 'POPDIST_NODE_DEVICE_ID=97' '-x' 'POPDIST_EXECUTABLE_CACHE_PATH=/home/wilsonb/tmp' '-x' 'POPDIST_REPLICA_INDEX_OFFSET=2' '-x' 'POPDIST_LOCAL_INSTANCE_INDEX=2' '-x' 'IPUOF_VIPU_API_HOST=10.1.3.101' '-x' 'IPUOF_VIPU_API_PORT=8090' '-x' 'IPUOF_VIPU_API_PARTITION_ID=p64' '-x' 'IPUOF_VIPU_API_TIMEOUT=120' '-x' 'IPUOF_LOG_LEVEL=WARN' '-x' 'PATH' '-x' 'LD_LIBRARY_PATH' '-x' 'PYTHONPATH' '-x' 'POPLAR_TARGET_OPTIONS={"ipuLinkDomainSize":"64","ipuLinkConfiguration":"slidingWindow","ipuLinkTopology":"mesh","gatewayMode":"true","instanceSize":"16"}' 'poprun_numa_wrapper' 'python' 'bin/exec.py' '--config-name=a21' 'mode=train' 'run.id=' 'run.distributed=False' 'data=real' 'data.data_directory=/lambda_stor/data/datascience/cosmic_tagging/' 'framework=torch' 'run.compute_mode=IPU' 'run.minibatch_size=2' 'run.iterations=10' 'run.precision=3' ':' '-np' '1' '-x' 'POPDIST_NUM_TOTAL_REPLICAS=4' '-x' 'POPDIST_NUM_IPUS_PER_REPLICA=1' '-x' 'POPDIST_NUM_LOCAL_REPLICAS=1' '-x' 'POPDIST_UNIFORM_REPLICAS_PER_INSTANCE=1' '-x' 'POPDIST_NODE_DEVICE_ID=97' '-x' 'POPDIST_EXECUTABLE_CACHE_PATH=/home/wilsonb/tmp' '-x' 'POPDIST_REPLICA_INDEX_OFFSET=3' '-x' 'POPDIST_LOCAL_INSTANCE_INDEX=3' '-x' 'IPUOF_VIPU_API_HOST=10.1.3.101' '-x' 'IPUOF_VIPU_API_PORT=8090' '-x' 'IPUOF_VIPU_API_PARTITION_ID=p64' '-x' 'IPUOF_VIPU_API_TIMEOUT=120' '-x' 'IPUOF_LOG_LEVEL=WARN' '-x' 'PATH' '-x' 'LD_LIBRARY_PATH' '-x' 'PYTHONPATH' '-x' 'POPLAR_TARGET_OPTIONS={"ipuLinkDomainSize":"64","ipuLinkConfiguration":"slidingWindow","ipuLinkTopology":"mesh","gatewayMode":"true","instanceSize":"16"}' 'poprun_numa_wrapper' 'python' 'bin/exec.py' '--config-name=a21' 'mode=train' 'run.id=' 'run.distributed=False' 'data=real' 'data.data_directory=/lambda_stor/data/datascience/cosmic_tagging/' 'framework=torch' 'run.compute_mode=IPU' 'run.minibatch_size=2' 'run.iterations=10' 'run.precision=3'
18:25:18.581 777907 POPRUN [I] Waiting for mpirun (PID 779009)
[1,1]<stdout>:2023-02-03 18:25:20,020 - INFO - Dumping launch arguments.
[1,1]<stdout>:2023-02-03 18:25:20,020 - INFO - ['bin/exec.py', '--config-name=a21', 'mode=train', 'run.id=', 'run.distributed=False', 'data=real', 'data.data_directory=/lambda_stor/data/datascience/cosmic_tagging/', 'framework=torch', 'run.compute_mode=IPU', 'run.minibatch_size=2', 'run.iterations=10', 'run.precision=3', 'hydra/job_logging=disabled']
[1,1]<stdout>:2023-02-03 18:25:20,020 - INFO - Running Training
[1,0]<stdout>:2023-02-03 18:25:20,020 - INFO - Dumping launch arguments.
[1,0]<stdout>:2023-02-03 18:25:20,021 - INFO - ['bin/exec.py', '--config-name=a21', 'mode=train', 'run.id=', 'run.distributed=False', 'data=real', 'data.data_directory=/lambda_stor/data/datascience/cosmic_tagging/', 'framework=torch', 'run.compute_mode=IPU', 'run.minibatch_size=2', 'run.iterations=10', 'run.precision=3', 'hydra/job_logging=disabled']
[1,0]<stdout>:2023-02-03 18:25:20,021 - INFO - Running Training
[1,3]<stdout>:2023-02-03 18:25:20,021 - INFO - Dumping launch arguments.
[1,3]<stdout>:2023-02-03 18:25:20,021 - INFO - ['bin/exec.py', '--config-name=a21', 'mode=train', 'run.id=', 'run.distributed=False', 'data=real', 'data.data_directory=/lambda_stor/data/datascience/cosmic_tagging/', 'framework=torch', 'run.compute_mode=IPU', 'run.minibatch_size=2', 'run.iterations=10', 'run.precision=3', 'hydra/job_logging=disabled']
[1,3]<stdout>:2023-02-03 18:25:20,021 - INFO - Running Training
[1,2]<stdout>:2023-02-03 18:25:20,023 - INFO - Dumping launch arguments.
[1,2]<stdout>:2023-02-03 18:25:20,023 - INFO - ['bin/exec.py', '--config-name=a21', 'mode=train', 'run.id=', 'run.distributed=False', 'data=real', 'data.data_directory=/lambda_stor/data/datascience/cosmic_tagging/', 'framework=torch', 'run.compute_mode=IPU', 'run.minibatch_size=2', 'run.iterations=10', 'run.precision=3', 'hydra/job_logging=disabled']
[1,2]<stdout>:2023-02-03 18:25:20,023 - INFO - Running Training
[1,1]<stdout>:2023-02-03 18:25:20,027 - INFO - 
[1,1]<stdout>:
[1,1]<stdout>:-- CONFIG --
[1,1]<stdout>:data: 
[1,1]<stdout>:  aux_file....................: cosmic_tagging_val.h5
[1,1]<stdout>:  data_directory..............: /lambda_stor/data/datascience/cosmic_tagging/
[1,1]<stdout>:  data_format.................: channels_first
[1,1]<stdout>:  downsample..................: 1
[1,1]<stdout>:  file........................: cosmic_tagging_train.h5
[1,1]<stdout>:  img_transform...............: False
[1,1]<stdout>:  synthetic...................: False
[1,1]<stdout>:framework: 
[1,1]<stdout>:  distributed_mode............: DDP
[1,1]<stdout>:  name........................: torch
[1,1]<stdout>:  sparse......................: False
[1,1]<stdout>:mode: 
[1,1]<stdout>:  checkpoint_iteration........: 500
[1,1]<stdout>:  logging_iteration...........: 1
[1,1]<stdout>:  name........................: train
[1,1]<stdout>:  no_summary_images...........: True
[1,1]<stdout>:  optimizer: 
[1,1]<stdout>:    gradient_accumulation.....: 1
[1,1]<stdout>:    learning_rate.............: 0.0003
[1,1]<stdout>:    loss_balance_scheme.......: focal
[1,1]<stdout>:    name......................: adam
[1,1]<stdout>:  quantization_aware..........: False
[1,1]<stdout>:  summary_iteration...........: 1
[1,1]<stdout>:  weights_location............: 
[1,1]<stdout>:network: 
[1,1]<stdout>:  bias........................: True
[1,1]<stdout>:  block_concat................: False
[1,1]<stdout>:  blocks_deepest_layer........: 5
[1,1]<stdout>:  blocks_final................: 5
[1,1]<stdout>:  blocks_per_layer............: 2
[1,1]<stdout>:  bottleneck_deepest..........: 256
[1,1]<stdout>:  connections.................: concat
[1,1]<stdout>:  conv_mode...................: conv_2D
[1,1]<stdout>:  data_format.................: channels_first
[1,1]<stdout>:  depth.......................: 6
[1,1]<stdout>:  downsampling................: max_pooling
[1,1]<stdout>:  filter_size_deepest.........: 5
[1,1]<stdout>:  growth_rate.................: additive
[1,1]<stdout>:  n_initial_filters...........: 8
[1,1]<stdout>:  name........................: A21
[1,1]<stdout>:  normalization...............: batch
[1,1]<stdout>:  residual....................: False
[1,1]<stdout>:  upsampling..................: interpolation
[1,1]<stdout>:  weight_decay................: 0.1
[1,1]<stdout>:output_dir....................: output/torch/A21//
[1,1]<stdout>:run: 
[1,1]<stdout>:  aux_iterations..............: 10
[1,1]<stdout>:  compute_mode................: IPU
[1,1]<stdout>:  distributed.................: False
[1,1]<stdout>:  id..........................: 
[1,1]<stdout>:  iterations..................: 10
[1,1]<stdout>:  minibatch_size..............: 2
[1,1]<stdout>:  precision...................: float16
[1,1]<stdout>:  profile.....................: False
[1,1]<stdout>:
[1,0]<stdout>:2023-02-03 18:25:20,027 - INFO - 
[1,0]<stdout>:
[1,0]<stdout>:-- CONFIG --
[1,0]<stdout>:data: 
[1,0]<stdout>:  aux_file....................: cosmic_tagging_val.h5
[1,0]<stdout>:  data_directory..............: /lambda_stor/data/datascience/cosmic_tagging/
[1,0]<stdout>:  data_format.................: channels_first
[1,0]<stdout>:  downsample..................: 1
[1,0]<stdout>:  file........................: cosmic_tagging_train.h5
[1,0]<stdout>:  img_transform...............: False
[1,0]<stdout>:  synthetic...................: False
[1,0]<stdout>:framework: 
[1,0]<stdout>:  distributed_mode............: DDP
[1,0]<stdout>:  name........................: torch
[1,0]<stdout>:  sparse......................: False
[1,0]<stdout>:mode: 
[1,0]<stdout>:  checkpoint_iteration........: 500
[1,0]<stdout>:  logging_iteration...........: 1
[1,0]<stdout>:  name........................: train
[1,0]<stdout>:  no_summary_images...........: True
[1,0]<stdout>:  optimizer: 
[1,0]<stdout>:    gradient_accumulation.....: 1
[1,0]<stdout>:    learning_rate.............: 0.0003
[1,0]<stdout>:    loss_balance_scheme.......: focal
[1,0]<stdout>:    name......................: adam
[1,0]<stdout>:  quantization_aware..........: False
[1,0]<stdout>:  summary_iteration...........: 1
[1,0]<stdout>:  weights_location............: 
[1,0]<stdout>:network: 
[1,0]<stdout>:  bias........................: True
[1,0]<stdout>:  block_concat................: False
[1,0]<stdout>:  blocks_deepest_layer........: 5
[1,0]<stdout>:  blocks_final................: 5
[1,0]<stdout>:  blocks_per_layer............: 2
[1,0]<stdout>:  bottleneck_deepest..........: 256
[1,0]<stdout>:  connections.................: concat
[1,0]<stdout>:  conv_mode...................: conv_2D
[1,0]<stdout>:  data_format.................: channels_first
[1,0]<stdout>:  depth.......................: 6
[1,0]<stdout>:  downsampling................: max_pooling
[1,0]<stdout>:  filter_size_deepest.........: 5
[1,0]<stdout>:  growth_rate.................: additive
[1,0]<stdout>:  n_initial_filters...........: 8
[1,0]<stdout>:  name........................: A21
[1,0]<stdout>:  normalization...............: batch
[1,0]<stdout>:  residual....................: False
[1,0]<stdout>:  upsampling..................: interpolation
[1,0]<stdout>:  weight_decay................: 0.1
[1,0]<stdout>:output_dir....................: output/torch/A21//
[1,0]<stdout>:run: 
[1,0]<stdout>:  aux_iterations..............: 10
[1,0]<stdout>:  compute_mode................: IPU
[1,0]<stdout>:  distributed.................: False
[1,0]<stdout>:  id..........................: 
[1,0]<stdout>:  iterations..................: 10
[1,0]<stdout>:  minibatch_size..............: 2
[1,0]<stdout>:  precision...................: float16
[1,0]<stdout>:  profile.....................: False
[1,0]<stdout>:
[1,3]<stdout>:2023-02-03 18:25:20,028 - INFO - 
[1,3]<stdout>:
[1,3]<stdout>:-- CONFIG --
[1,3]<stdout>:data: 
[1,3]<stdout>:  aux_file....................: cosmic_tagging_val.h5
[1,3]<stdout>:  data_directory..............: /lambda_stor/data/datascience/cosmic_tagging/
[1,3]<stdout>:  data_format.................: channels_first
[1,3]<stdout>:  downsample..................: 1
[1,3]<stdout>:  file........................: cosmic_tagging_train.h5
[1,3]<stdout>:  img_transform...............: False
[1,3]<stdout>:  synthetic...................: False
[1,3]<stdout>:framework: 
[1,3]<stdout>:  distributed_mode............: DDP
[1,3]<stdout>:  name........................: torch
[1,3]<stdout>:  sparse......................: False
[1,3]<stdout>:mode: 
[1,3]<stdout>:  checkpoint_iteration........: 500
[1,3]<stdout>:  logging_iteration...........: 1
[1,3]<stdout>:  name........................: train
[1,3]<stdout>:  no_summary_images...........: True
[1,3]<stdout>:  optimizer: 
[1,3]<stdout>:    gradient_accumulation.....: 1
[1,3]<stdout>:    learning_rate.............: 0.0003
[1,3]<stdout>:    loss_balance_scheme.......: focal
[1,3]<stdout>:    name......................: adam
[1,3]<stdout>:  quantization_aware..........: False
[1,3]<stdout>:  summary_iteration...........: 1
[1,3]<stdout>:  weights_location............: 
[1,3]<stdout>:network: 
[1,3]<stdout>:  bias........................: True
[1,3]<stdout>:  block_concat................: False
[1,3]<stdout>:  blocks_deepest_layer........: 5
[1,3]<stdout>:  blocks_final................: 5
[1,3]<stdout>:  blocks_per_layer............: 2
[1,3]<stdout>:  bottleneck_deepest..........: 256
[1,3]<stdout>:  connections.................: concat
[1,3]<stdout>:  conv_mode...................: conv_2D
[1,3]<stdout>:  data_format.................: channels_first
[1,3]<stdout>:  depth.......................: 6
[1,3]<stdout>:  downsampling................: max_pooling
[1,3]<stdout>:  filter_size_deepest.........: 5
[1,3]<stdout>:  growth_rate.................: additive
[1,3]<stdout>:  n_initial_filters...........: 8
[1,3]<stdout>:  name........................: A21
[1,3]<stdout>:  normalization...............: batch
[1,3]<stdout>:  residual....................: False
[1,3]<stdout>:  upsampling..................: interpolation
[1,3]<stdout>:  weight_decay................: 0.1
[1,3]<stdout>:output_dir....................: output/torch/A21//
[1,3]<stdout>:run: 
[1,3]<stdout>:  aux_iterations..............: 10
[1,3]<stdout>:  compute_mode................: IPU
[1,3]<stdout>:  distributed.................: False
[1,3]<stdout>:  id..........................: 
[1,3]<stdout>:  iterations..................: 10
[1,3]<stdout>:  minibatch_size..............: 2
[1,3]<stdout>:  precision...................: float16
[1,3]<stdout>:  profile.....................: False
[1,3]<stdout>:
[1,2]<stdout>:2023-02-03 18:25:20,029 - INFO - 
[1,2]<stdout>:
[1,2]<stdout>:-- CONFIG --
[1,2]<stdout>:data: 
[1,2]<stdout>:  aux_file....................: cosmic_tagging_val.h5
[1,2]<stdout>:  data_directory..............: /lambda_stor/data/datascience/cosmic_tagging/
[1,2]<stdout>:  data_format.................: channels_first
[1,2]<stdout>:  downsample..................: 1
[1,2]<stdout>:  file........................: cosmic_tagging_train.h5
[1,2]<stdout>:  img_transform...............: False
[1,2]<stdout>:  synthetic...................: False
[1,2]<stdout>:framework: 
[1,2]<stdout>:  distributed_mode............: DDP
[1,2]<stdout>:  name........................: torch
[1,2]<stdout>:  sparse......................: False
[1,2]<stdout>:mode: 
[1,2]<stdout>:  checkpoint_iteration........: 500
[1,2]<stdout>:  logging_iteration...........: 1
[1,2]<stdout>:  name........................: train
[1,2]<stdout>:  no_summary_images...........: True
[1,2]<stdout>:  optimizer: 
[1,2]<stdout>:    gradient_accumulation.....: 1
[1,2]<stdout>:    learning_rate.............: 0.0003
[1,2]<stdout>:    loss_balance_scheme.......: focal
[1,2]<stdout>:    name......................: adam
[1,2]<stdout>:  quantization_aware..........: False
[1,2]<stdout>:  summary_iteration...........: 1
[1,2]<stdout>:  weights_location............: 
[1,2]<stdout>:network: 
[1,2]<stdout>:  bias........................: True
[1,2]<stdout>:  block_concat................: False
[1,2]<stdout>:  blocks_deepest_layer........: 5
[1,2]<stdout>:  blocks_final................: 5
[1,2]<stdout>:  blocks_per_layer............: 2
[1,2]<stdout>:  bottleneck_deepest..........: 256
[1,2]<stdout>:  connections.................: concat
[1,2]<stdout>:  conv_mode...................: conv_2D
[1,2]<stdout>:  data_format.................: channels_first
[1,2]<stdout>:  depth.......................: 6
[1,2]<stdout>:  downsampling................: max_pooling
[1,2]<stdout>:  filter_size_deepest.........: 5
[1,2]<stdout>:  growth_rate.................: additive
[1,2]<stdout>:  n_initial_filters...........: 8
[1,2]<stdout>:  name........................: A21
[1,2]<stdout>:  normalization...............: batch
[1,2]<stdout>:  residual....................: False
[1,2]<stdout>:  upsampling..................: interpolation
[1,2]<stdout>:  weight_decay................: 0.1
[1,2]<stdout>:output_dir....................: output/torch/A21//
[1,2]<stdout>:run: 
[1,2]<stdout>:  aux_iterations..............: 10
[1,2]<stdout>:  compute_mode................: IPU
[1,2]<stdout>:  distributed.................: False
[1,2]<stdout>:  id..........................: 
[1,2]<stdout>:  iterations..................: 10
[1,2]<stdout>:  minibatch_size..............: 2
[1,2]<stdout>:  precision...................: float16
[1,2]<stdout>:  profile.....................: False
[1,2]<stdout>:
[1,1]<stdout>:2023-02-03 18:25:23,921 - INFO - Larcv file prepared
[1,2]<stdout>:2023-02-03 18:25:23,991 - INFO - Larcv file prepared
[1,0]<stdout>:2023-02-03 18:25:23,991 - INFO - Larcv file prepared
[1,3]<stdout>:2023-02-03 18:25:23,992 - INFO - Larcv file prepared
[1,1]<stdout>:2023-02-03 18:25:24,083 - INFO - Larcv file prepared
[1,3]<stdout>:2023-02-03 18:25:24,084 - INFO - Larcv file prepared
[1,0]<stdout>:2023-02-03 18:25:24,092 - INFO - Larcv file prepared
[1,2]<stdout>:2023-02-03 18:25:24,102 - INFO - Larcv file prepared
[1,3]<stdout>:2023-02-03 18:25:24,207 - INFO - Total number of trainable parameters in this network: 8525699
[1,0]<stdout>:2023-02-03 18:25:24,215 - INFO - Total number of trainable parameters in this network: 8525699
[1,2]<stdout>:2023-02-03 18:25:24,224 - INFO - Total number of trainable parameters in this network: 8525699
[1,1]<stdout>:2023-02-03 18:25:24,224 - INFO - Total number of trainable parameters in this network: 8525699
[1,3]<stderr>:2023-02-03 18:25:24.232875: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
[1,3]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,0]<stderr>:2023-02-03 18:25:24.234662: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
[1,0]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,1]<stderr>:2023-02-03 18:25:24.245932: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
[1,1]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,2]<stderr>:2023-02-03 18:25:24.246637: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
[1,2]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,3]<stderr>:2023-02-03 18:25:24.359601: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/popart-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib
[1,3]<stderr>:2023-02-03 18:25:24.359635: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
[1,0]<stderr>:2023-02-03 18:25:24.371565: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/popart-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib
[1,0]<stderr>:2023-02-03 18:25:24.371604: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
[1,1]<stderr>:2023-02-03 18:25:24.385562: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/popart-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib
[1,1]<stderr>:2023-02-03 18:25:24.385596: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
[1,2]<stderr>:2023-02-03 18:25:24.387046: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/popart-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib
[1,2]<stderr>:2023-02-03 18:25:24.387084: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
[1,1]<stderr>:2023-02-03 18:25:27.644328: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/popart-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib
[1,0]<stderr>:2023-02-03 18:25:27.644329: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/popart-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib
[1,1]<stderr>:2023-02-03 18:25:27.644405: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/popart-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib
[1,1]<stderr>:2023-02-03 18:25:27.644410: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
[1,0]<stderr>:2023-02-03 18:25:27.644415: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/popart-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib
[1,0]<stderr>:2023-02-03 18:25:27.644421: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
[1,2]<stderr>:2023-02-03 18:25:27.644936: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/popart-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib
[1,2]<stderr>:2023-02-03 18:25:27.645009: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/popart-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib
[1,2]<stderr>:2023-02-03 18:25:27.645015: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
[1,3]<stderr>:2023-02-03 18:25:27.644991: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/popart-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib
[1,3]<stderr>:2023-02-03 18:25:27.645058: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/popart-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib
[1,3]<stderr>:2023-02-03 18:25:27.645064: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
[1,0]<stdout>:2023-02-03 18:25:33,489 - INFO - No checkpoint file found, restarting from scratch
[1,3]<stdout>:2023-02-03 18:25:33,491 - INFO - No checkpoint file found, restarting from scratch
[1,2]<stdout>:2023-02-03 18:25:33,497 - INFO - No checkpoint file found, restarting from scratch
[1,1]<stdout>:2023-02-03 18:25:33,498 - INFO - No checkpoint file found, restarting from scratch
[1,0]<stdout>:2023-02-03 18:25:47,567 - INFO - train Step 0 metrics: Average/Non_Bkg_Accuracy: 0.17, Average/mIoU: 0.00193, loss: 3.89 (0.018 IOs / 0.05 (Step)(s))
[1,1]<stdout>:2023-02-03 18:25:47,609 - INFO - train Step 0 metrics: Average/Non_Bkg_Accuracy: 0.152, Average/mIoU: 0.0029, loss: 3.94 (0.02 IOs / 0.053 (Step)(s))
[1,3]<stdout>:2023-02-03 18:25:47,963 - INFO - train Step 0 metrics: Average/Non_Bkg_Accuracy: 0.16, Average/mIoU: 0.00113, loss: 3.81 (0.018 IOs / 0.05 (Step)(s))
[1,2]<stdout>:2023-02-03 18:25:48,054 - INFO - train Step 0 metrics: Average/Non_Bkg_Accuracy: 0.244, Average/mIoU: 0.00281, loss: 3.78 (0.018 IOs / 0.051 (Step)(s))
[1,0]<stdout>:2023-02-03 18:26:00,734 - INFO - train Step 1 metrics: Average/Non_Bkg_Accuracy: 0.169, Average/mIoU: 0.000991, loss: 3.73 (0.15 Img/s / 0.018 IOs / 0.04 (Step)(s))
[1,1]<stdout>:2023-02-03 18:26:00,913 - INFO - train Step 1 metrics: Average/Non_Bkg_Accuracy: 0.157, Average/mIoU: 0.00137, loss: 3.81 (0.15 Img/s / 0.026 IOs / 0.04 (Step)(s))
[1,2]<stdout>:2023-02-03 18:26:01,461 - INFO - train Step 1 metrics: Average/Non_Bkg_Accuracy: 0.127, Average/mIoU: 0.00155, loss: 3.94 (0.15 Img/s / 0.016 IOs / 0.04 (Step)(s))
[1,3]<stdout>:2023-02-03 18:26:03,575 - INFO - train Step 1 metrics: Average/Non_Bkg_Accuracy: 0.15, Average/mIoU: 0.00114, loss: 3.84 (0.13 Img/s / 0.024 IOs / 0.08 (Step)(s))
[1,0]<stdout>:2023-02-03 18:26:13,706 - INFO - train Step 2 metrics: Average/Non_Bkg_Accuracy: 0.111, Average/mIoU: 0.000666, loss: 3.89 (0.15 Img/s / 0.013 IOs / 0.047 (Step)(s))
[1,1]<stdout>:2023-02-03 18:26:13,929 - INFO - train Step 2 metrics: Average/Non_Bkg_Accuracy: 0.182, Average/mIoU: 0.0023, loss: 3.76 (0.15 Img/s / 0.013 IOs / 0.045 (Step)(s))
[1,2]<stdout>:2023-02-03 18:26:14,625 - INFO - train Step 2 metrics: Average/Non_Bkg_Accuracy: 0.152, Average/mIoU: 0.000873, loss: 3.74 (0.15 Img/s / 0.012 IOs / 0.04 (Step)(s))
[1,3]<stdout>:2023-02-03 18:26:17,746 - INFO - train Step 2 metrics: Average/Non_Bkg_Accuracy: 0.112, Average/mIoU: 0.00125, loss: 3.9 (0.14 Img/s / 0.029 IOs / 0.048 (Step)(s))
[1,0]<stdout>:2023-02-03 18:26:26,535 - INFO - train Step 3 metrics: Average/Non_Bkg_Accuracy: 0.138, Average/mIoU: 0.000801, loss: 3.79 (0.16 Img/s / 0.016 IOs / 0.038 (Step)(s))
[1,1]<stdout>:2023-02-03 18:26:26,780 - INFO - train Step 3 metrics: Average/Non_Bkg_Accuracy: 0.229, Average/mIoU: 0.00391, loss: 3.72 (0.16 Img/s / 0.018 IOs / 0.038 (Step)(s))
[1,2]<stdout>:2023-02-03 18:26:27,594 - INFO - train Step 3 metrics: Average/Non_Bkg_Accuracy: 0.211, Average/mIoU: 0.00377, loss: 3.9 (0.15 Img/s / 0.016 IOs / 0.045 (Step)(s))
[1,3]<stdout>:2023-02-03 18:26:31,555 - INFO - train Step 3 metrics: Average/Non_Bkg_Accuracy: 0.15, Average/mIoU: 0.00181, loss: 3.87 (0.14 Img/s / 0.017 IOs / 0.049 (Step)(s))
[1,0]<stdout>:2023-02-03 18:26:39,468 - INFO - train Step 4 metrics: Average/Non_Bkg_Accuracy: 0.13, Average/mIoU: 0.00164, loss: 3.95 (0.15 Img/s / 0.014 IOs / 0.044 (Step)(s))
[1,1]<stdout>:2023-02-03 18:26:39,702 - INFO - train Step 4 metrics: Average/Non_Bkg_Accuracy: 0.194, Average/mIoU: 0.00308, loss: 3.86 (0.15 Img/s / 0.013 IOs / 0.046 (Step)(s))
[1,2]<stdout>:2023-02-03 18:26:40,575 - INFO - train Step 4 metrics: Average/Non_Bkg_Accuracy: 0.193, Average/mIoU: 0.00286, loss: 3.75 (0.15 Img/s / 0.013 IOs / 0.041 (Step)(s))
[1,3]<stdout>:2023-02-03 18:26:44,951 - INFO - train Step 4 metrics: Average/Non_Bkg_Accuracy: 0.178, Average/mIoU: 0.00208, loss: 3.88 (0.15 Img/s / 0.019 IOs / 0.045 (Step)(s))
[1,0]<stdout>:2023-02-03 18:26:52,270 - INFO - train Step 5 metrics: Average/Non_Bkg_Accuracy: 0.174, Average/mIoU: 0.00228, loss: 3.75 (0.16 Img/s / 0.016 IOs / 0.04 (Step)(s))
[1,1]<stdout>:2023-02-03 18:26:52,530 - INFO - train Step 5 metrics: Average/Non_Bkg_Accuracy: 0.147, Average/mIoU: 0.00123, loss: 3.89 (0.16 Img/s / 0.019 IOs / 0.041 (Step)(s))
[1,2]<stdout>:2023-02-03 18:26:53,675 - INFO - train Step 5 metrics: Average/Non_Bkg_Accuracy: 0.0991, Average/mIoU: 0.000524, loss: 3.89 (0.15 Img/s / 0.021 IOs / 0.044 (Step)(s))
[1,3]<stdout>:2023-02-03 18:26:58,328 - INFO - train Step 5 metrics: Average/Non_Bkg_Accuracy: 0.136, Average/mIoU: 0.00194, loss: 3.97 (0.15 Img/s / 0.016 IOs / 0.046 (Step)(s))
[1,0]<stdout>:2023-02-03 18:27:05,038 - INFO - train Step 6 metrics: Average/Non_Bkg_Accuracy: 0.193, Average/mIoU: 0.00226, loss: 3.8 (0.16 Img/s / 0.013 IOs / 0.041 (Step)(s))
[1,1]<stdout>:2023-02-03 18:27:05,322 - INFO - train Step 6 metrics: Average/Non_Bkg_Accuracy: 0.129, Average/mIoU: 0.00144, loss: 3.93 (0.16 Img/s / 0.013 IOs / 0.038 (Step)(s))
[1,2]<stdout>:2023-02-03 18:27:06,602 - INFO - train Step 6 metrics: Average/Non_Bkg_Accuracy: 0.136, Average/mIoU: 0.00157, loss: 3.86 (0.15 Img/s / 0.014 IOs / 0.041 (Step)(s))
[1,3]<stdout>:2023-02-03 18:27:11,580 - INFO - train Step 6 metrics: Average/Non_Bkg_Accuracy: 0.164, Average/mIoU: 0.00295, loss: 3.87 (0.15 Img/s / 0.016 IOs / 0.049 (Step)(s))
[1,0]<stdout>:2023-02-03 18:27:17,739 - INFO - train Step 7 metrics: Average/Non_Bkg_Accuracy: 0.162, Average/mIoU: 0.00148, loss: 3.79 (0.16 Img/s / 0.015 IOs / 0.044 (Step)(s))
[1,1]<stdout>:2023-02-03 18:27:18,073 - INFO - train Step 7 metrics: Average/Non_Bkg_Accuracy: 0.198, Average/mIoU: 0.0024, loss: 3.74 (0.16 Img/s / 0.013 IOs / 0.045 (Step)(s))
[1,2]<stdout>:2023-02-03 18:27:19,436 - INFO - train Step 7 metrics: Average/Non_Bkg_Accuracy: 0.145, Average/mIoU: 0.00102, loss: 3.85 (0.16 Img/s / 0.014 IOs / 0.041 (Step)(s))
[1,3]<stdout>:2023-02-03 18:27:26,478 - INFO - train Step 7 metrics: Average/Non_Bkg_Accuracy: 0.228, Average/mIoU: 0.0028, loss: 3.8 (0.13 Img/s / 0.017 IOs / 0.079 (Step)(s))
[1,0]<stdout>:2023-02-03 18:27:30,484 - INFO - train Step 8 metrics: Average/Non_Bkg_Accuracy: 0.116, Average/mIoU: 0.000897, loss: 3.84 (0.16 Img/s / 0.014 IOs / 0.039 (Step)(s))
[1,1]<stdout>:2023-02-03 18:27:30,796 - INFO - train Step 8 metrics: Average/Non_Bkg_Accuracy: 0.194, Average/mIoU: 0.0036, loss: 3.86 (0.16 Img/s / 0.019 IOs / 0.041 (Step)(s))
[1,2]<stdout>:2023-02-03 18:27:32,406 - INFO - train Step 8 metrics: Average/Non_Bkg_Accuracy: 0.131, Average/mIoU: 0.00112, loss: 3.9 (0.15 Img/s / 0.015 IOs / 0.046 (Step)(s))
[1,3]<stdout>:2023-02-03 18:27:41,639 - INFO - train Step 8 metrics: Average/Non_Bkg_Accuracy: 0.129, Average/mIoU: 0.00105, loss: 3.85 (0.13 Img/s / 0.05 IOs / 0.067 (Step)(s))
[1,0]<stdout>:2023-02-03 18:27:43,328 - INFO - train Step 9 metrics: Average/Non_Bkg_Accuracy: 0.205, Average/mIoU: 0.00115, loss: 3.82 (0.16 Img/s / 0.014 IOs / 0.038 (Step)(s))
[1,0]<stdout>:2023-02-03 18:27:43,340 - INFO - Saving run profile information.
[1,0]<stdout>:2023-02-03 18:27:43,352 - INFO - Total time to batch_process: 129.8631
[1,0]<stdout>:2023-02-03 18:27:43,353 - INFO - Total time to batch process except first iteration: 115.7811, throughput: 0.1555
[1,0]<stdout>:2023-02-03 18:27:43,353 - INFO - Total time to batch process except first two iterations: 102.5974, throughput: 0.1559
[1,1]<stdout>:2023-02-03 18:27:43,692 - INFO - train Step 9 metrics: Average/Non_Bkg_Accuracy: 0.148, Average/mIoU: 0.00191, loss: 3.81 (0.16 Img/s / 0.013 IOs / 0.038 (Step)(s))
[1,1]<stdout>:2023-02-03 18:27:43,706 - INFO - Saving run profile information.
[1,1]<stdout>:2023-02-03 18:27:43,717 - INFO - Total time to batch_process: 130.2185
[1,1]<stdout>:2023-02-03 18:27:43,717 - INFO - Total time to batch process except first iteration: 116.1028, throughput: 0.1550
[1,1]<stdout>:2023-02-03 18:27:43,717 - INFO - Total time to batch process except first two iterations: 102.7877, throughput: 0.1557
[1,2]<stdout>:2023-02-03 18:27:45,100 - INFO - train Step 9 metrics: Average/Non_Bkg_Accuracy: 0.105, Average/mIoU: 0.000517, loss: 3.82 (0.16 Img/s / 0.016 IOs / 0.038 (Step)(s))
[1,2]<stdout>:2023-02-03 18:27:45,110 - INFO - Saving run profile information.
[1,2]<stdout>:2023-02-03 18:27:45,118 - INFO - Total time to batch_process: 131.6211
[1,2]<stdout>:2023-02-03 18:27:45,120 - INFO - Total time to batch process except first iteration: 117.0609, throughput: 0.1538
[1,2]<stdout>:2023-02-03 18:27:45,120 - INFO - Total time to batch process except first two iterations: 103.6513, throughput: 0.1544
[1,3]<stdout>:2023-02-03 18:27:55,094 - INFO - train Step 9 metrics: Average/Non_Bkg_Accuracy: 0.173, Average/mIoU: 0.00181, loss: 3.72 (0.15 Img/s / 0.025 IOs / 0.05 (Step)(s))
[1,3]<stdout>:2023-02-03 18:27:55,118 - INFO - Saving run profile information.
[1,3]<stdout>:2023-02-03 18:27:55,127 - INFO - Total time to batch_process: 141.6355
[1,3]<stdout>:2023-02-03 18:27:55,127 - INFO - Total time to batch process except first iteration: 127.1591, throughput: 0.1416
[1,3]<stdout>:2023-02-03 18:27:55,127 - INFO - Total time to batch process except first two iterations: 111.5423, throughput: 0.1434
18:27:55.894 777907 POPRUN [I] mpirun (PID 779009) terminated with exit code 0
