diff --git a/requirements.txt b/requirements.txt
index 6e8a7b9..e959223 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -1,8 +1,8 @@
 numpy
 h5py
 larcv
-tensorflow>=2.4.0
-torch>=1.3
+# tensorflow>=2.4.0
+# torch>=1.3
 Pillow # Needed for tensorboardX
 tensorboardX
 hydra-core==1.1
diff --git a/src/config/config.py b/src/config/config.py
index b060114..9d0a090 100644
--- a/src/config/config.py
+++ b/src/config/config.py
@@ -15,6 +15,7 @@ class ComputeMode(Enum):
     GPU   = 1
     DPCPP = 2
     XPU   = 3
+    HPU   = 4

 class Precision(Enum):
     float32  = 0
@@ -40,6 +41,7 @@ class Run:
     id:                 str         = MISSING
     precision:          Precision   = Precision.float32
     profile:            bool        = False
+    lazy_mode:          bool        = False

 cs = ConfigStore.instance()

diff --git a/src/config/data.py b/src/config/data.py
index 7daba3e..bf5596b 100644
--- a/src/config/data.py
+++ b/src/config/data.py
@@ -30,4 +30,4 @@ class Synthetic(Data):

 cs = ConfigStore.instance()
 cs.store(group="data", name="real", node=Real)
-cs.store(group="data", name="synthetic", node=Synthetic)
\ No newline at end of file
+cs.store(group="data", name="synthetic", node=Synthetic)
diff --git a/src/utils/tensorflow2/trainer.py b/src/utils/tensorflow2/trainer.py
index 69cc804..e0ab814 100644
--- a/src/utils/tensorflow2/trainer.py
+++ b/src/utils/tensorflow2/trainer.py
@@ -183,6 +183,9 @@ class tf_trainer(trainercore):

     def initialize(self, io_only=False):

+        if self.args.run.compute_mode == ComputeMode.HPU:
+            from habana_frameworks.tensorflow import load_habana_module
+            load_habana_module()

         self._initialize_io(color=0)


diff --git a/src/utils/torch/distributed_trainer.py b/src/utils/torch/distributed_trainer.py
index 433ba96..e8a21c6 100644
--- a/src/utils/torch/distributed_trainer.py
+++ b/src/utils/torch/distributed_trainer.py
@@ -16,6 +16,7 @@ try:
 except:
     pass

+import contextlib
 import logging
 logger = logging.getLogger()
 logger.propogate = False
@@ -98,7 +99,10 @@ class distributed_trainer(torch_trainer):
             size = MPI.COMM_WORLD.Get_size()
             rank = MPI.COMM_WORLD.Get_rank()

-            torch.cuda.set_device(int(local_rank))
+            if self.args.run.compute_mode == ComputeMode.HPU:
+                import habana_frameworks.torch.distributed.hccl
+            else:
+                torch.cuda.set_device(int(local_rank))
             os.environ["RANK"] = str(rank)


@@ -131,17 +135,24 @@ class distributed_trainer(torch_trainer):
                 backend = 'ccl'
             elif self.args.run.compute_mode == ComputeMode.GPU: backend = 'nccl'
             elif self.args.run.compute_mode == ComputeMode.CPU: backend = 'gloo'
+            elif self.args.run.compute_mode == ComputeMode.HPU: backend = 'hccl'



             # init_method = 'file:///home/cadams/ddp_init/ddp_init.txt'
             init_method = 'env://'

-            torch.distributed.init_process_group(
-                backend     = backend,
-                init_method = init_method,
-                world_size  = size,
-                rank        = rank,
-                timeout     = datetime.timedelta(seconds=120)
-            )
+            if self.args.run.compute_mode == ComputeMode.HPU:
+                # Here we assume the number of process per node is 8
+                os.environ["ID"] = str(rank % 8 )
+                os.environ["LOCAL_RANK"] = str(rank % 8 )
+                torch.distributed.init_process_group(backend=backend, rank=rank, world_size=size)
+            else:
+                torch.distributed.init_process_group(
+                    backend     = backend,
+                    init_method = init_method,
+                    world_size  = size,
+                    rank        = rank,
+                    timeout     = datetime.timedelta(seconds=120)
+                )





     def save_model(self):
@@ -169,7 +180,7 @@ class distributed_trainer(torch_trainer):
             return contextlib.nullcontext
             # device = torch.device("dpcpp")
         else:
-            return contextlib.nullcontext
+            return contextlib.nullcontext()
             # device = torch.device('cpu')

     def default_device(self):
@@ -184,6 +195,8 @@ class distributed_trainer(torch_trainer):
             device = torch.device(f"xpu:{self._local_rank}")
         elif self.args.run.compute_mode == ComputeMode.DPCPP:
             device = torch.device("dpcpp")
+        elif self.args.run.compute_mode == ComputeMode.HPU:
+            device = torch.device("hpu")
         else:
             device = torch.device('cpu')
         return device





diff --git a/src/utils/torch/trainer.py b/src/utils/torch/trainer.py
index 71b6cf3..46a6fb7 100644
--- a/src/utils/torch/trainer.py
+++ b/src/utils/torch/trainer.py
@@ -1,4 +1,6 @@
 import os
+from pickle import TRUE
+from re import I
 import sys
 import time
 import tempfile


@@ -96,6 +98,16 @@ class torch_trainer(trainercore):
         if self.is_training():
             self.build_lr_schedule()

+        if self.args.run.compute_mode == ComputeMode.HPU:
+
+            import habana_frameworks.torch.core as htcore
+            self.htcore = htcore
+
+            if self.args.run.lazy_mode:
+                os.environ["PT_HPU_LAZY_MODE"]="1"
+            else:
+                os.environ["PT_HPU_LAZY_MODE"]="2"
+
         with self.default_device_context():
             self.init_network()



@@ -462,7 +474,7 @@ class torch_trainer(trainercore):

             # Build up a string for logging:
             if self._log_keys != []:
-                s = ", ".join(["{0}: {1:.3}".format(key, metrics[key]) for key in self._log_keys])
+                s = ", ".join(["{0}: {1:.3}".format(key, metrics[key].item()) for key in self._log_keys])
             else:
                 s = ", ".join(["{0}: {1:.3}".format(key, metrics[key]) for key in metrics])

@@ -598,8 +610,10 @@ class torch_trainer(trainercore):
         # elif self.args.run.compute_mode == "DPCPP":
         #     return contextlib.nullcontext
         #     # device = torch.device("dpcpp")
+        elif self.args.run.compute_mode == ComputeMode.HPU:
+            return contextlib.nullcontext()
         else:
-            return contextlib.nullcontext
+            return contextlib.nullcontext()
             # device = torch.device('cpu')

     def default_device(self):
@@ -610,6 +624,8 @@ class torch_trainer(trainercore):
             device = torch.device("xpu")
         # elif self.args.run.compute_mode == "DPCPP":
         #     device = torch.device("dpcpp")
+        elif self.args.run.compute_mode == ComputeMode.HPU:
+            device = torch.device("hpu")
         else:
             device = torch.device('cpu')
         return device
@@ -733,8 +749,8 @@ class torch_trainer(trainercore):
                     else:
                         loss.backward()

-
-
+                    if self.args.run.lazy_mode:
+                        self.htcore.mark_step()

                     # Compute any necessary metrics:
                     interior_metrics = self._compute_metrics(logits_image, labels_image, loss)
@@ -776,6 +792,9 @@ class torch_trainer(trainercore):
             else:
                 self._opt.step()

+            if self.args.run.lazy_mode:
+                self.htcore.mark_step()
+
             self.lr_scheduler.step()

             if verbose: logger.debug("Updated Weights")
@@ -816,30 +835,31 @@ class torch_trainer(trainercore):
         # fit onto a gpu or other accelerator
         if self._global_step != 0 and self._global_step % self.args.run.aux_iterations == 0:

-            self._net.eval()
-            # Fetch the next batch of data with larcv
-            # (Make sure to pull from the validation set)
-            io_start_time = datetime.datetime.now()
-            minibatch_data = self.larcv_fetcher.fetch_next_batch('aux', force_pop = True)
-            io_end_time = datetime.datetime.now()
+            with torch.no_grad():
+                self._net.eval()
+                # Fetch the next batch of data with larcv
+                # (Make sure to pull from the validation set)
+                io_start_time = datetime.datetime.now()
+                minibatch_data = self.larcv_fetcher.fetch_next_batch('aux', force_pop = True)
+                io_end_time = datetime.datetime.now()

-            # if mixed precision, and cuda, use autocast:
-            if self.args.run.precision == Precision.mixed and self.args.run.compute_mode == ComputeMode.GPU:
-                with torch.cuda.amp.autocast():
+                # if mixed precision, and cuda, use autocast:
+                if self.args.run.precision == Precision.mixed and self.args.run.compute_mode == ComputeMode.GPU:
+                    with torch.cuda.amp.autocast():
+                        logits_image, labels_image = self.forward_pass(minibatch_data)
+                else:
                     logits_image, labels_image = self.forward_pass(minibatch_data)
-            else:
-                logits_image, labels_image = self.forward_pass(minibatch_data)

-            # Compute the loss based on the logits
-            loss = self.loss_calculator(labels_image, logits_image)
+                # Compute the loss based on the logits
+                loss = self.loss_calculator(labels_image, logits_image)

-            # Compute any necessary metrics:
-            metrics = self._compute_metrics(logits_image, labels_image, loss)
+                # Compute any necessary metrics:
+                metrics = self._compute_metrics(logits_image, labels_image, loss)


-            self.log(metrics, saver="test")
-            self.summary(metrics, saver="test")
-            self.summary_images(logits_image, labels_image, saver="test")
+                self.log(metrics, saver="test")
+                self.summary(metrics, saver="test")
+                self.summary_images(logits_image, labels_image, saver="test")

             return

