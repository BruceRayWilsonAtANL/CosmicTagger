18:18:43.337 773189 POPRUN [I] V-IPU server address picked up from 'vipu': 10.1.3.101:8090
18:18:43.340 773189 POPRUN [I] Using V-IPU partition p64 as it is the only one available
18:18:43.340 773189 POPRUN [D] Connecting to 10.1.3.101:8090
18:18:43.343 773189 POPRUN [D] Status for partition p64: OK (error 0)
18:18:43.343 773189 POPRUN [I] Partition p64 already exists and is in state: PS_ACTIVE
18:18:43.344 773189 POPRUN [D] The reconfigurable partition p64 is OK
 ===============
| poprun top... |
|===============|
| hosts     | . |
|-----------|---|
| ILDs      | 0 |
|-----------|---|
| instances | 0 |
|-----------|---|
| replicas  | 0 |
 ---------------
[0]: localhost
18:18:43.346 773189 POPRUN [D] Target options from environment: {}
18:18:43.346 773189 POPRUN [D] Target options from V-IPU partition: {"ipuLinkDomainSize":"64","ipuLinkConfiguration":"slidingWindow","ipuLinkTopology":"mesh","gatewayMode":"true","instanceSize":"64"}
18:18:43.873 773189 POPRUN [D] Found 64 devices with 1 IPUs
18:18:44.629 773189 POPRUN [D] Attached to device 0
18:18:44.629 773189 POPRUN [I] Preparing parent device 0
18:18:44.630 773189 POPRUN [D] Device 0 ipuLinkDomainSize=64, ipuLinkConfiguration=Default, ipuLinkTopology=Mesh, gatewayMode=true, instanceSize=1
18:18:46.789 773189 POPRUN [D] Target options from Poplar device: {"ipuLinkDomainSize":"64","ipuLinkConfiguration":"default","ipuLinkTopology":"mesh","gatewayMode":"true","instanceSize":"1"}
18:18:46.789 773189 POPRUN [D] Using target options: {"ipuLinkDomainSize":"64","ipuLinkConfiguration":"slidingWindow","ipuLinkTopology":"mesh","gatewayMode":"true","instanceSize":"64"}
18:18:46.818 773189 POPRUN [D] Skipping port 1 of IB device uverbs0 because its state (1) doesn't seem active. Information in sysfs might be invalid or might not exist
18:18:46.824 773189 POPRUN [D] Skipping port 1 of IB device uverbs1 because its state (1) doesn't seem active. Information in sysfs might be invalid or might not exist
18:18:46.838 773189 POPRUN [D] No hosts specified; ignoring host-subnet setting
18:18:46.838 773189 POPRUN [D] Default network/RNIC for host communication: None
18:18:46.839 773189 POPRUN [I] Running command: /software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/bin/mpirun '--bind-to' 'none' '--tag-output' '--allow-run-as-root' '-np' '1' '-x' 'POPDIST_NUM_TOTAL_REPLICAS=1' '-x' 'POPDIST_NUM_IPUS_PER_REPLICA=1' '-x' 'POPDIST_NUM_LOCAL_REPLICAS=1' '-x' 'POPDIST_UNIFORM_REPLICAS_PER_INSTANCE=1' '-x' 'POPDIST_NODE_DEVICE_ID=0' '-x' 'POPDIST_EXECUTABLE_CACHE_PATH=/home/wilsonb/tmp' '-x' 'POPDIST_REPLICA_INDEX_OFFSET=0' '-x' 'POPDIST_LOCAL_INSTANCE_INDEX=0' '-x' 'IPUOF_VIPU_API_HOST=10.1.3.101' '-x' 'IPUOF_VIPU_API_PORT=8090' '-x' 'IPUOF_VIPU_API_PARTITION_ID=p64' '-x' 'IPUOF_VIPU_API_TIMEOUT=120' '-x' 'IPUOF_LOG_LEVEL=WARN' '-x' 'PATH' '-x' 'LD_LIBRARY_PATH' '-x' 'PYTHONPATH' '-x' 'POPLAR_TARGET_OPTIONS={"ipuLinkDomainSize":"64","ipuLinkConfiguration":"slidingWindow","ipuLinkTopology":"mesh","gatewayMode":"true","instanceSize":"64"}' 'python' 'bin/exec.py' '--config-name=a21' 'mode=train' 'run.id=' 'run.distributed=False' 'data=real' 'data.data_directory=/lambda_stor/data/datascience/cosmic_tagging/' 'framework=torch' 'run.compute_mode=IPU' 'run.minibatch_size=2' 'run.iterations=10' 'run.precision=3'
18:18:46.849 773189 POPRUN [I] Waiting for mpirun (PID 773747)
[1,0]<stdout>:2023-02-03 18:18:47,890 - INFO - Dumping launch arguments.
[1,0]<stdout>:2023-02-03 18:18:47,890 - INFO - ['bin/exec.py', '--config-name=a21', 'mode=train', 'run.id=', 'run.distributed=False', 'data=real', 'data.data_directory=/lambda_stor/data/datascience/cosmic_tagging/', 'framework=torch', 'run.compute_mode=IPU', 'run.minibatch_size=2', 'run.iterations=10', 'run.precision=3', 'hydra/job_logging=disabled']
[1,0]<stdout>:2023-02-03 18:18:47,890 - INFO - Running Training
[1,0]<stdout>:2023-02-03 18:18:47,897 - INFO - 
[1,0]<stdout>:
[1,0]<stdout>:-- CONFIG --
[1,0]<stdout>:data: 
[1,0]<stdout>:  aux_file....................: cosmic_tagging_val.h5
[1,0]<stdout>:  data_directory..............: /lambda_stor/data/datascience/cosmic_tagging/
[1,0]<stdout>:  data_format.................: channels_first
[1,0]<stdout>:  downsample..................: 1
[1,0]<stdout>:  file........................: cosmic_tagging_train.h5
[1,0]<stdout>:  img_transform...............: False
[1,0]<stdout>:  synthetic...................: False
[1,0]<stdout>:framework: 
[1,0]<stdout>:  distributed_mode............: DDP
[1,0]<stdout>:  name........................: torch
[1,0]<stdout>:  sparse......................: False
[1,0]<stdout>:mode: 
[1,0]<stdout>:  checkpoint_iteration........: 500
[1,0]<stdout>:  logging_iteration...........: 1
[1,0]<stdout>:  name........................: train
[1,0]<stdout>:  no_summary_images...........: True
[1,0]<stdout>:  optimizer: 
[1,0]<stdout>:    gradient_accumulation.....: 1
[1,0]<stdout>:    learning_rate.............: 0.0003
[1,0]<stdout>:    loss_balance_scheme.......: focal
[1,0]<stdout>:    name......................: adam
[1,0]<stdout>:  quantization_aware..........: False
[1,0]<stdout>:  summary_iteration...........: 1
[1,0]<stdout>:  weights_location............: 
[1,0]<stdout>:network: 
[1,0]<stdout>:  bias........................: True
[1,0]<stdout>:  block_concat................: False
[1,0]<stdout>:  blocks_deepest_layer........: 5
[1,0]<stdout>:  blocks_final................: 5
[1,0]<stdout>:  blocks_per_layer............: 2
[1,0]<stdout>:  bottleneck_deepest..........: 256
[1,0]<stdout>:  connections.................: concat
[1,0]<stdout>:  conv_mode...................: conv_2D
[1,0]<stdout>:  data_format.................: channels_first
[1,0]<stdout>:  depth.......................: 6
[1,0]<stdout>:  downsampling................: max_pooling
[1,0]<stdout>:  filter_size_deepest.........: 5
[1,0]<stdout>:  growth_rate.................: additive
[1,0]<stdout>:  n_initial_filters...........: 8
[1,0]<stdout>:  name........................: A21
[1,0]<stdout>:  normalization...............: batch
[1,0]<stdout>:  residual....................: False
[1,0]<stdout>:  upsampling..................: interpolation
[1,0]<stdout>:  weight_decay................: 0.1
[1,0]<stdout>:output_dir....................: output/torch/A21//
[1,0]<stdout>:run: 
[1,0]<stdout>:  aux_iterations..............: 10
[1,0]<stdout>:  compute_mode................: IPU
[1,0]<stdout>:  distributed.................: False
[1,0]<stdout>:  id..........................: 
[1,0]<stdout>:  iterations..................: 10
[1,0]<stdout>:  minibatch_size..............: 2
[1,0]<stdout>:  precision...................: float16
[1,0]<stdout>:  profile.....................: False
[1,0]<stdout>:
[1,0]<stdout>:2023-02-03 18:18:50,563 - INFO - Larcv file prepared
[1,0]<stdout>:2023-02-03 18:18:50,667 - INFO - Larcv file prepared
[1,0]<stdout>:2023-02-03 18:18:50,809 - INFO - Total number of trainable parameters in this network: 8525699
[1,0]<stderr>:2023-02-03 18:18:50.832449: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
[1,0]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,0]<stderr>:2023-02-03 18:18:50.941188: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/popart-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib
[1,0]<stderr>:2023-02-03 18:18:50.941223: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
[1,0]<stderr>:2023-02-03 18:18:53.048194: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/popart-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib
[1,0]<stderr>:2023-02-03 18:18:53.048260: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/popart-ubuntu_20_04-3.1.0+6824-9c103dc348/lib:/software/graphcore/poplar_sdk/3.1.0/poplar-ubuntu_20_04-3.1.0+6824-9c103dc348/lib
[1,0]<stderr>:2023-02-03 18:18:53.048267: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
[1,0]<stdout>:2023-02-03 18:18:56,611 - INFO - No checkpoint file found, restarting from scratch
[1,0]<stdout>:2023-02-03 18:19:11,035 - INFO - train Step 0 metrics: Average/Non_Bkg_Accuracy: 0.164, Average/mIoU: 0.00188, loss: 3.86 (0.018 IOs / 0.061 (Step)(s))
[1,0]<stdout>:2023-02-03 18:19:27,625 - INFO - train Step 1 metrics: Average/Non_Bkg_Accuracy: 0.232, Average/mIoU: 0.00551, loss: 3.73 (0.12 Img/s / 0.019 IOs / 0.071 (Step)(s))
[1,0]<stdout>:2023-02-03 18:19:40,772 - INFO - train Step 2 metrics: Average/Non_Bkg_Accuracy: 0.154, Average/mIoU: 0.00181, loss: 3.86 (0.15 Img/s / 0.037 IOs / 0.046 (Step)(s))
[1,0]<stdout>:2023-02-03 18:19:53,635 - INFO - train Step 3 metrics: Average/Non_Bkg_Accuracy: 0.123, Average/mIoU: 0.00175, loss: 3.97 (0.16 Img/s / 0.017 IOs / 0.046 (Step)(s))
[1,0]<stdout>:2023-02-03 18:20:06,298 - INFO - train Step 4 metrics: Average/Non_Bkg_Accuracy: 0.129, Average/mIoU: 0.000799, loss: 3.8 (0.16 Img/s / 0.015 IOs / 0.039 (Step)(s))
[1,0]<stdout>:2023-02-03 18:20:19,008 - INFO - train Step 5 metrics: Average/Non_Bkg_Accuracy: 0.181, Average/mIoU: 0.00261, loss: 3.83 (0.16 Img/s / 0.013 IOs / 0.039 (Step)(s))
[1,0]<stdout>:2023-02-03 18:20:31,284 - INFO - train Step 6 metrics: Average/Non_Bkg_Accuracy: 0.154, Average/mIoU: 0.00267, loss: 3.91 (0.16 Img/s / 0.015 IOs / 0.042 (Step)(s))
[1,0]<stdout>:2023-02-03 18:20:43,846 - INFO - train Step 7 metrics: Average/Non_Bkg_Accuracy: 0.118, Average/mIoU: 0.00105, loss: 3.96 (0.16 Img/s / 0.014 IOs / 0.041 (Step)(s))
[1,0]<stdout>:2023-02-03 18:20:56,494 - INFO - train Step 8 metrics: Average/Non_Bkg_Accuracy: 0.128, Average/mIoU: 0.000861, loss: 3.89 (0.16 Img/s / 0.014 IOs / 0.039 (Step)(s))
[1,0]<stdout>:2023-02-03 18:21:09,305 - INFO - train Step 9 metrics: Average/Non_Bkg_Accuracy: 0.181, Average/mIoU: 0.00384, loss: 3.92 (0.16 Img/s / 0.014 IOs / 0.039 (Step)(s))
[1,0]<stdout>:2023-02-03 18:21:09,320 - INFO - Saving run profile information.
[1,0]<stdout>:2023-02-03 18:21:09,328 - INFO - Total time to batch_process: 132.7163
[1,0]<stdout>:2023-02-03 18:21:09,328 - INFO - Total time to batch process except first iteration: 118.2892, throughput: 0.1522
[1,0]<stdout>:2023-02-03 18:21:09,329 - INFO - Total time to batch process except first two iterations: 101.6958, throughput: 0.1573
18:21:10.060 773189 POPRUN [I] mpirun (PID 773747) terminated with exit code 0
